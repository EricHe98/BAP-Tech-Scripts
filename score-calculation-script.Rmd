---
title: "Score-Calculations-Script"
author: "Eric He"
date: "September 1, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library("googlesheets") # manipulate google sheets
library("dplyr") # munge data
library("jsonlite") # write to JSON
library("purrr") # functionals
library("stringr") # text processing
library("magrittr") # pipes
library("readxl")
library("reshape2")

orgsync_file <- "type-speaker_pnt-2_pen-0_sem-spring-2017_name-BAP-E-Board-Elections-Participation.xlsx"
gs_auth()

sheets_url <- "https://docs.google.com/spreadsheets/d/1PzNG2zPv1m9wQ081_0A9Y89MlQrd_yzRdaeC7ZPlwCc/edit#gid=0"
key <- sheets_url %>%
  extract_key_from_url %>%
  gs_key(lookup = FALSE, visibility = "private") # need these settings to add rows

member_event_tech_mat <- gs_read_csv("event_member", ss = key)
event_info <- gs_read_csv("event_info", ss = key, stringsAsFactors = FALSE)

member_event_cm_mat <- "set up the google sheets here"
#member_event_tech_mat <- "set up"

# if (nrow(member_event_cm_mat) != nrow(member_event_tech_mat) | ncol(member_event_cm_mat) != ncol(member_event_tech_mat)){
#  stop("CM and Tech Committee data have differing member and/or event counts")}

raw_output <- read_excel(orgsync_file, sheet = "Participation")

event_name <- str_extract(orgsync_file, pattern = "(?<=name-).*?(?=\\.)") %>% str_to_lower()
event_type <- str_extract(orgsync_file, pattern = "(?m)(?<=type-)(speaker)|(community)|(social)(?=_)") %>% str_to_lower()
event_points <- str_extract(orgsync_file, pattern = "(?<=pnt-)[\\d]{1,2}(?=_)") %>% as.numeric
event_penalty <- str_extract(orgsync_file, pattern = "(?<=pen-)[\\d]{1,2}(?=_)") %>% as.numeric
event_semester <- str_extract(orgsync_file, pattern = "(?<=sem-)((spring)|(fall))-[\\d]+(?=_)") %>% str_to_lower

new_event <- data_frame(event_name, event_type, event_points, event_penalty, event_semester)
event_info %<>% rbind(new_event)

netID_vec <- str_extract(raw_output$Email, pattern = ".*?(?=@)")
event_attendees <- data_frame(NetID = netID_vec, event_name = TRUE) %>%
  set_colnames(c(colnames(.)[-ncol(.)], event_name))

updated_member_event_tech_mat <- full_join(member_event_tech_mat, event_attendees, by = "NetID") %>%
  mutate_all(~replace(., which(is.na(.)), FALSE))

melted <- melt(updated_member_event_tech_mat, id = "NetID", variable.name = "event_name", value.name = "attended") %>%
  left_join(event_info, by = "event_name")

updated_points <- group_by(melted, NetID, event_type) %>%
  summarise(total_points = sum(event_points * attended - event_penalty * !attended)) %>%
  spread(key = "event_type", value = "total_points")

write.csv(updated_member_event_tech_mat, row.names = FALSE, file = "member_event.csv")
gs_upload("member_event.csv", sheet_title = "member_event_tech_mat", overwrite = TRUE)

write.csv(event_info, row.names = FALSE, file = "event_info.csv")
gs_upload("event_info.csv", sheet_title = "event_info", overwrite = TRUE)

write.csv(updated_points, row.names = FALSE, file = "point_scores.csv")
gs_upload("point_scores.csv", sheet_title = "point_scores", overwrite = TRUE)

melted$attended[melted$attended == TRUE] <- "Attended"
melted$attended[melted$attended == FALSE] <- "Unattended"

big_list <- list()
medium_list <- list()
small_list <- list()

b <- split(melted, list(melted$NetID, melted$event_type, melted$attended)) %>%
  map(select, event_name)



for (name in melted$NetID[1:10]){
  for (type in melted$event_type){
    for (attendance in melted$attended){
      small_list[[attendance]] <- b[[(paste(name, type, attendance, sep = "."))]]
    }
    medium_list[[type]] <- small_list
  }
  big_list[[name]] <- medium_list
}

#approximately 2 seconds per person

#replace [] with null
#delete [] when characters are in between [ and ]

attendance_json <- toJSON(big_list, pretty = TRUE)

event_types <- unique(event_info$event_type)
map(event_types, ~filter(event_info, event_type == .))
filter(event_info, event_type == "community") -> b
member_event_tech_mat[,colnames(member_event_tech_mat) %in% c("NetID", b)]

```
